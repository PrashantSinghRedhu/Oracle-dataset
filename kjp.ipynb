{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "797968\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "797968\n",
      "[[ 0.00238044  0.00186163]\n",
      " [ 0.00564592  0.00503555]\n",
      " [-0.00186163  0.00051881]\n",
      " ...\n",
      " [ 0.00097659  0.00100711]\n",
      " [-0.00244148 -0.00140385]\n",
      " [ 0.00112918 -0.001648  ]]\n",
      "yvalshape: (157968,)\n",
      "yvalshape1: (157968, 16)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(3197968, 2, 128) [2, 128]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import os\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "# os.environ[\"THEANO_FLAGS\"]  = \"device=cuda%d\"%(6)\n",
    "import numpy as np\n",
    "# import theano as th\n",
    "# import tensorflow as T\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "# from keras.optimizers import adam\n",
    "from keras.regularizers import l2\n",
    "# from keras import regularizers\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import keras\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "from scipy.io import loadmat\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import load_model\n",
    "\n",
    "# RESHAPING INPUT\n",
    "# x=y.reshape(15640,2,128)\n",
    "\n",
    "dist = '14'\n",
    "n_classes = 16\n",
    "file1 = 'IQ' + str(n_classes) + '_' + dist + 'ft_train_' + str(n_classes * 200) + 'K.mat'\n",
    "f = h5py.File(file1, 'r')\n",
    "X = f.get('MatrixData')\n",
    "X = np.array(X)\n",
    "X = X.transpose()\n",
    "X_train = X.astype('float32')\n",
    "#\n",
    "# del X\n",
    "#\n",
    "l2_lambda = 0.0001\n",
    "seg = 128\n",
    "#\n",
    "X_trainsize = (X_train.shape[0] // (seg))\n",
    "# print(X_trainsize)\n",
    "L = X_train[:, 0].reshape(X_trainsize, 1, seg)\n",
    "M = X_train[:, 1].reshape(X_trainsize, 1, seg)\n",
    "\n",
    "\n",
    "meanL = np.mean(L)\n",
    "meanM = np.mean(M)\n",
    "std_L = np.std(L)\n",
    "std_M = np.std(M)\n",
    "\n",
    "L = L - meanL\n",
    "M = M - meanM\n",
    "\n",
    "L = L / std_L\n",
    "M = M / std_M\n",
    "\n",
    "X_train = np.concatenate([L, M], axis=1)\n",
    "\n",
    "del L, M\n",
    "\n",
    "y_trainsize = X_trainsize // n_classes\n",
    "y_train = []\n",
    "\n",
    "for idx in range(0, n_classes):\n",
    "    y_train = np.concatenate((y_train, idx * np.ones(y_trainsize, )), axis=0)\n",
    "\n",
    "# temp = zip(X_train,y_train)\n",
    "# temp = [x for x in temp]\n",
    "# np.random.shuffle(temp)\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "# for x,y in temp:\n",
    "#     X_train.append(x)\n",
    "#     y_train.append(y)\n",
    "y_train_old = y_train.copy()\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "print(y_train[20:])\n",
    "file2 = 'IQ' + str(n_classes) + '_' + dist + 'ft_test_' + str(n_classes * 50) + 'K.mat'\n",
    "f = h5py.File(file2, 'r')\n",
    "X = f.get('MatrixData')\n",
    "X = np.array(X)\n",
    "X = X.transpose()\n",
    "X_test = X.astype('float32')\n",
    "\n",
    "del X\n",
    "\n",
    "# matFile = 'Disp128_test_200K.mat'\n",
    "# mat = loadmat(matFile)\n",
    "# X_test= mat['MatrixData']\n",
    "X_testsize = (X_test.shape[0] // (seg))\n",
    "\n",
    "print(X_testsize)\n",
    "\n",
    "L = X_test[:, 0].reshape(X_testsize, 1, seg)\n",
    "M = X_test[:, 1].reshape(X_testsize, 1, seg)\n",
    "\n",
    "L = L - meanL\n",
    "M = M - meanM\n",
    "\n",
    "L = L / std_L\n",
    "M = M / std_M\n",
    "\n",
    "X_test = np.concatenate([L, M], axis=1)\n",
    "\n",
    "del L, M\n",
    "\n",
    "y_testsize = X_testsize // n_classes\n",
    "\n",
    "y_test = []\n",
    "for idx in range(0, n_classes):\n",
    "    y_test = np.concatenate((y_test, idx * np.ones(y_testsize, )), axis=0)\n",
    "\n",
    "# temp = zip(X_test,y_test)\n",
    "# temp = [x for x in temp]\n",
    "# np.random.shuffle(temp)\n",
    "# X_test = []\n",
    "# y_test = []\n",
    "# for x,y in temp:\n",
    "#     X_test.append(x)\n",
    "#     y_test.append(y)\n",
    "# y1 = np.zeros(y_testsize,)\n",
    "# y2 = np.ones(y_testsize,)\n",
    "# y3 = 2*np.ones(y_testsize,)\n",
    "# y4 = 3*np.ones(y_testsize,)\n",
    "# y5 = 4*np.ones(y_testsize,)\n",
    "# y_test = np.concatenate((y1,y2, y3, y4,y5), axis=0)\n",
    "y_test_old = y_test.copy()\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(y_test[20:])\n",
    "\n",
    "print(len(y_test))\n",
    "# del y1, y2, y3, y4,y5\n",
    "\n",
    "# test_idx = np.random.choice(range(0,X_testsize), size=X_testsize, replace=False)\n",
    "#\n",
    "# X_test=X_test[test_idx]\n",
    "# y_test=y_test[test_idx]\n",
    "file3 = 'IQ' + str(n_classes) + '_' + dist + 'ft_validation_' + str(n_classes * 10) + 'K.mat'\n",
    "f = h5py.File(file3, 'r')\n",
    "X = f.get('MatrixData')\n",
    "X = np.array(X)\n",
    "X = X.transpose()\n",
    "X_val = X.astype('float32')\n",
    "\n",
    "del X\n",
    "\n",
    "X_valsize = (X_val.shape[0] // (seg))\n",
    "print(X_val)\n",
    "L = X_val[:, 0].reshape(X_valsize, 1, seg)\n",
    "M = X_val[:, 1].reshape(X_valsize, 1, seg)\n",
    "\n",
    "L = L - meanL\n",
    "M = M - meanM\n",
    "\n",
    "L = L / std_L\n",
    "M = M / std_M\n",
    "\n",
    "X_val = np.concatenate([L, M], axis=1)\n",
    "\n",
    "del L, M\n",
    "\n",
    "y_valsize = X_valsize // n_classes\n",
    "y_val = []\n",
    "\n",
    "for idx in range(0, n_classes):\n",
    "    y_val = np.concatenate((y_val, idx * np.ones(y_valsize, )), axis=0)\n",
    "\n",
    "# temp = zip(X_val,y_val)\n",
    "# temp = [x for x in temp]\n",
    "# np.random.shuffle(temp)\n",
    "# X_val = []\n",
    "# y_val = []\n",
    "# for x, y in temp:\n",
    "#     X_val.append(x)\n",
    "#     y_val.append(y)\n",
    "print(\"yvalshape:\",y_val.shape)\n",
    "y_val_old = y_val.copy()\n",
    "y_val = np_utils.to_categorical(y_val, n_classes)\n",
    "print(\"yvalshape1:\",y_val.shape)\n",
    "\n",
    "print(y_val[20:])\n",
    "k_scores = []\n",
    "roc_all = []\n",
    "fpr_all = []\n",
    "tpr_all = []\n",
    "overacc_all = []\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "in_shp = list(X_train.shape[1:])\n",
    "print(X_train.shape, in_shp)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40439808\n",
      "40439808\n"
     ]
    }
   ],
   "source": [
    "print(157968*2*128)\n",
    "print(2* 20219904)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1, 2, 128)         0         \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPadding  (None, 1, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 1, 1, 50)          6450      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 1, 50)          0         \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 1, 5, 50)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 1, 1, 50)          10050     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 1, 50)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 256)               13056     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 80)                20560     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 80)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 16)                1296      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,412\n",
      "Trainable params: 51,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3124/3124 - 55s - loss: 2.7751 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 55s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "3124/3124 - 48s - loss: 2.7726 - accuracy: 0.0623 - val_loss: 2.7726 - val_accuracy: 0.0625 - 48s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "3124/3124 - 47s - loss: 2.7726 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 47s/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "3124/3124 - 47s - loss: 2.7726 - accuracy: 0.0628 - val_loss: 2.7726 - val_accuracy: 0.0625 - 47s/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "3124/3124 - 45s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 45s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "3124/3124 - 44s - loss: 2.7726 - accuracy: 0.0624 - val_loss: 2.7726 - val_accuracy: 0.0625 - 44s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "3124/3124 - 49s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 49s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "3124/3124 - 44s - loss: 2.7726 - accuracy: 0.0623 - val_loss: 2.7726 - val_accuracy: 0.0625 - 44s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "3124/3124 - 43s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 43s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "3124/3124 - 49s - loss: 2.7726 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 49s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "3124/3124 - 46s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 46s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "3124/3124 - 43s - loss: 2.7726 - accuracy: 0.0623 - val_loss: 2.7726 - val_accuracy: 0.0625 - 43s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "3124/3124 - 43s - loss: 2.7726 - accuracy: 0.0624 - val_loss: 2.7726 - val_accuracy: 0.0625 - 43s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "3124/3124 - 52s - loss: 2.7726 - accuracy: 0.0624 - val_loss: 2.7726 - val_accuracy: 0.0625 - 52s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "3124/3124 - 55s - loss: 2.7726 - accuracy: 0.0627 - val_loss: 2.7726 - val_accuracy: 0.0625 - 55s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "3124/3124 - 45s - loss: 2.7726 - accuracy: 0.0622 - val_loss: 2.7726 - val_accuracy: 0.0625 - 45s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "3124/3124 - 41s - loss: 2.7726 - accuracy: 0.0624 - val_loss: 2.7726 - val_accuracy: 0.0625 - 41s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "3124/3124 - 47s - loss: 2.7726 - accuracy: 0.0623 - val_loss: 2.7726 - val_accuracy: 0.0625 - 47s/epoch - 15ms/step\n",
      "Epoch 19/100\n",
      "3124/3124 - 47s - loss: 2.7726 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 47s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "3124/3124 - 48s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 48s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "3124/3124 - 48s - loss: 2.7726 - accuracy: 0.0621 - val_loss: 2.7726 - val_accuracy: 0.0625 - 48s/epoch - 15ms/step\n",
      "Epoch 22/100\n",
      "3124/3124 - 44s - loss: 2.7726 - accuracy: 0.0623 - val_loss: 2.7726 - val_accuracy: 0.0625 - 44s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "3124/3124 - 41s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 41s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "3124/3124 - 42s - loss: 2.7726 - accuracy: 0.0624 - val_loss: 2.7726 - val_accuracy: 0.0625 - 42s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "3124/3124 - 44s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 44s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "3124/3124 - 43s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 43s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "3124/3124 - 42s - loss: 2.7726 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625 - 42s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "3124/3124 - 43s - loss: 2.7726 - accuracy: 0.0622 - val_loss: 2.7726 - val_accuracy: 0.0625 - 43s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "3124/3124 - 41s - loss: 2.7726 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 41s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "3124/3124 - 41s - loss: 2.7726 - accuracy: 0.0626 - val_loss: 2.7726 - val_accuracy: 0.0625 - 41s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "3124/3124 - 45s - loss: 2.7726 - accuracy: 0.0621 - val_loss: 2.7726 - val_accuracy: 0.0625 - 45s/epoch - 14ms/step\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10612/2612512481.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;31m#   - call the main training loop in keras for our network+dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[0mfilepath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'IQ_dense_'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'_'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdist\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'ft.h5'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m history = model.fit(X_train,\n\u001B[0m\u001B[0;32m     41\u001B[0m                     \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1214\u001B[0m                 _r=1):\n\u001B[0;32m   1215\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1216\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1217\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    909\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 910\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    911\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    940\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    941\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 942\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    943\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    944\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3128\u001B[0m       (graph_function,\n\u001B[0;32m   3129\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3130\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   3131\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   3132\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1957\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1958\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1959\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1961\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    596\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    597\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 598\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    600\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     60\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "\n",
    "\n",
    "dr = 0.5  # dropout rate (%)\n",
    "flt1 = 50\n",
    "flt2 = 50\n",
    "taps = 7\n",
    "model = models.Sequential()\n",
    "model.add(Reshape([1] + in_shp, input_shape=in_shp))\n",
    "model.add(ZeroPadding2D((0, 2)))\n",
    "model.add(Conv2D(flt1, 1, taps, padding='same', name=\"conv1\", kernel_regularizer=l2(l2_lambda),\n",
    "                        kernel_initializer='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(ZeroPadding2D((0, 2)))\n",
    "model.add(Conv2D(flt2, 2, taps, padding=\"same\", name=\"conv2\", kernel_regularizer=l2(l2_lambda),\n",
    "                        kernel_initializer='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, kernel_initializer='he_normal', kernel_regularizer=l2(l2_lambda), name=\"dense1\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Dense(80, kernel_initializer='he_normal', kernel_regularizer=l2(l2_lambda), name=\"dense2\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Dense(n_classes, kernel_initializer='he_normal', kernel_regularizer=l2(l2_lambda), name=\"dense3\"))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Reshape([n_classes]))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Set up some params\n",
    "nb_epoch = 100  # number of epochs to train on\n",
    "batch_size = 1024  # training batch size\n",
    "\n",
    "# perform training ...\n",
    "#   - call the main training loop in keras for our network+dataset\n",
    "filepath = 'IQ_dense_' + str(n_classes) + '_' + dist + 'ft.h5'\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[\n",
    "                        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                                        mode='auto'),\n",
    "                        # keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "                    ])\n",
    "\n",
    "# model.save('disp_small_slide1_8M_model.h5')\n",
    "# we re-load the best weights once training is finished\n",
    "# Assuming you have code for instantiating your model,\n",
    "# you can then load the weights you saved into a model with the same architecture:\n",
    "model.save(filepath)\n",
    "\n",
    "# Show simple version of performance\n",
    "score = model.evaluate(X_test, y_test, verbose=0, batch_size=batch_size)\n",
    "print(score)\n",
    "k_scores.append(score)\n",
    "\n",
    "# Plot confusion matrix\n",
    "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
    "conf = np.zeros([n_classes, n_classes])\n",
    "confnorm = np.zeros([n_classes, n_classes])\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    j = list(y_test[i, :]).index(1)\n",
    "    k = int(np.argmax(test_Y_hat[i, :]))\n",
    "    conf[j, k] = conf[j, k] + 1\n",
    "print(\"confusion matrix\")\n",
    "print(conf)\n",
    "for i in range(0, n_classes):\n",
    "    confnorm[i, :] = conf[i, :] / np.sum(conf[i, :])\n",
    "print(\"confnormal\")\n",
    "print(confnorm)\n",
    "cor = np.sum(np.diag(conf))\n",
    "ncor = np.sum(conf) - cor\n",
    "overacc = cor / (cor + ncor)\n",
    "print(\"Overall Accuracy: \", overacc)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], test_Y_hat[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "roc_all.append(roc_auc)\n",
    "fpr_all.append(fpr)\n",
    "tpr_all.append(tpr)\n",
    "overacc_all.append(overacc)\n",
    "\n",
    "meanacc = np.mean(overacc_all)\n",
    "\n",
    "file_pickle = 'IQ_dense_' + str(n_classes) + '_' + dist + 'ft.pickle'\n",
    "with open(file_pickle, 'w') as f:\n",
    "    # Python 3: open(..., 'wb')\n",
    "    pickle.dump([roc_all, fpr_all, tpr_all, overacc_all, meanacc], f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328],\n       [0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328],\n       [0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328],\n       ...,\n       [0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328],\n       [0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328],\n       [0.0627927 , 0.06175638, 0.06315552, ..., 0.06215895, 0.06212903,\n        0.06249328]], dtype=float32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0625"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]\n",
      " [    0.     0. 49873.     0.     0.     0.     0.     0.     0.     0.\n",
      "      0.     0.     0.     0.     0.     0.]]\n"
     ]
    }
   ],
   "source": [
    "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
    "conf = np.zeros([n_classes, n_classes])\n",
    "confnorm = np.zeros([n_classes, n_classes])\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    j = list(y_test[i, :]).index(1)\n",
    "    k = int(np.argmax(test_Y_hat[i, :]))\n",
    "    conf[j, k] = conf[j, k] + 1\n",
    "print(\"confusion matrix\")\n",
    "print(conf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(797968, 16)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}